{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Optimizasyonu\n",
    "\n",
    "Bu notebook hiperparametre optimizasyonu ve model karÅŸÄ±laÅŸtÄ±rmasÄ± iÃ§erir.\n",
    "\n",
    "**Ä°Ã§erik:**\n",
    "1. Veri HazÄ±rlÄ±ÄŸÄ± ve Feature Engineering\n",
    "2. LightGBM Hiperparametre Optimizasyonu\n",
    "3. XGBoost Hiperparametre Optimizasyonu\n",
    "4. Model KarÅŸÄ±laÅŸtÄ±rmasÄ±\n",
    "5. Final Model SeÃ§imi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Veri YÃ¼kleme ve Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = Path('../data/raw/')\n",
    "df = pd.read_csv(DATA_PATH / 'bank.csv')\n",
    "\n",
    "\n",
    "TARGET = 'deposit'\n",
    "y = (df[TARGET] == 'yes').astype(int)\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "print(f'Veri yÃ¼klendi: {df.shape[0]:,} satÄ±r, {df.shape[1]} sÃ¼tun')\n",
    "\n",
    "# === FEATURE ENGINEERING (03 notebook'tan) ===\n",
    "X_fe = X.copy()\n",
    "\n",
    "# 1. Duration Ã§Ä±kar\n",
    "X_fe = X_fe.drop(columns=['duration'])\n",
    "\n",
    "# 2. YaÅŸ gruplarÄ±\n",
    "X_fe['age_group'] = pd.cut(\n",
    "    X_fe['age'], \n",
    "    bins=[0, 30, 40, 50, 60, 100],\n",
    "    labels=['18-30', '31-40', '41-50', '51-60', '60+']\n",
    ")\n",
    "\n",
    "# 3. Bakiye kategorileri\n",
    "X_fe['balance_category'] = pd.cut(\n",
    "    X_fe['balance'],\n",
    "    bins=[-np.inf, 0, 100, 500, 2000, np.inf],\n",
    "    labels=['Negatif', 'Dusuk', 'Orta', 'Yuksek', 'Cok Yuksek']\n",
    ")\n",
    "\n",
    "# 4. Never contacted flag\n",
    "X_fe['never_contacted'] = (X_fe['pdays'] == -1).astype(int)\n",
    "\n",
    "# 5. Mevsimsellik\n",
    "month_map = {\n",
    "    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "    'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
    "}\n",
    "X_fe['month_numeric'] = X_fe['month'].map(month_map)\n",
    "X_fe['quarter'] = ((X_fe['month_numeric'] - 1) // 3) + 1\n",
    "X_fe['is_year_end'] = (X_fe['month_numeric'].isin([11, 12])).astype(int)\n",
    "X_fe['is_year_start'] = (X_fe['month_numeric'].isin([1, 2])).astype(int)\n",
    "\n",
    "# 6. Kampanya metrikleri\n",
    "X_fe['total_contacts'] = X_fe['campaign'] + X_fe['previous']\n",
    "X_fe['over_contacted'] = (X_fe['campaign'] > 5).astype(int)\n",
    "\n",
    "# 7. Ä°nteraksiyon feature'larÄ±\n",
    "X_fe['age_balance_interaction'] = X_fe['age'] * (X_fe['balance'] / 1000)\n",
    "X_fe['age_campaign_interaction'] = X_fe['age'] * X_fe['campaign']\n",
    "\n",
    "# 8. Ratio\n",
    "X_fe['balance_per_age'] = X_fe['balance'] / (X_fe['age'] + 1)\n",
    "\n",
    "# Label Encoding\n",
    "cat_cols = X_fe.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_fe[col] = le.fit_transform(X_fe[col].astype(str))\n",
    "\n",
    "print(f'Feature Engineering tamamlandÄ±: {X_fe.shape[1]} feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split ve Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_fe, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f'Train: {X_train.shape[0]:,} Ã¶rnek')\n",
    "print(f'Test:  {X_test.shape[0]:,} Ã¶rnek')\n",
    "\n",
    "# Baseline skoru\n",
    "baseline_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=RANDOM_STATE, verbose=-1)\n",
    "baseline_scores = cross_val_score(baseline_model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "print(f'\\nBaseline CV AUC: {baseline_scores.mean():.4f} (+/- {baseline_scores.std():.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LightGBM Hiperparametre Optimizasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"LightGBM Hiperparametre Optimizasyonu\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# GeniÅŸletilmiÅŸ parametre grid'i + regularization\n",
    "lgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'num_leaves': [31, 50, 70],\n",
    "    'max_depth': [5, 7, 10],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1],      # L1 regularization\n",
    "    'reg_lambda': [0, 1],       # L2 regularization\n",
    "}\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(random_state=RANDOM_STATE, verbose=-1, n_jobs=-1)\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "lgb_grid = RandomizedSearchCV(\n",
    "    lgb_model,\n",
    "    lgb_param_grid,\n",
    "    n_iter=50,  # 50 random komb.\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "lgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\nEn iyi parametreler: {lgb_grid.best_params_}')\n",
    "print(f'En iyi CV AUC: {lgb_grid.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. XGBoost Hiperparametre Optimizasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"XGBoost Hiperparametre Optimizasyonu\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# GeniÅŸletilmiÅŸ parametre grid'i + regularization\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 0.9],\n",
    "    'colsample_bytree': [0.8, 0.9],\n",
    "    'reg_alpha': [0, 0.1],      # L1 regularization\n",
    "    'reg_lambda': [1, 2],       # L2 regularization\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    random_state=RANDOM_STATE, \n",
    "    eval_metric='logloss',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#randomized search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgb_grid = RandomizedSearchCV(\n",
    "    xgb_model,\n",
    "    xgb_param_grid,\n",
    "    n_iter=50,  # 50 random kombinasyon\n",
    "    cv=3,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f'\\nEn iyi parametreler: {xgb_grid.best_params_}')\n",
    "print(f'En iyi CV AUC: {xgb_grid.best_score_:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model KarÅŸÄ±laÅŸtÄ±rmasÄ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"MODEL KARÅžILAÅžTIRMASI\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# En iyi modeller\n",
    "best_lgb = lgb_grid.best_estimator_\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "# Test seti tahminleri\n",
    "lgb_pred_proba = best_lgb.predict_proba(X_test)[:, 1]\n",
    "xgb_pred_proba = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Test AUC\n",
    "lgb_test_auc = roc_auc_score(y_test, lgb_pred_proba)\n",
    "xgb_test_auc = roc_auc_score(y_test, xgb_pred_proba)\n",
    "\n",
    "# SonuÃ§lar tablosu\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['LightGBM', 'XGBoost'],\n",
    "    'CV AUC': [lgb_grid.best_score_, xgb_grid.best_score_],\n",
    "    'Test AUC': [lgb_test_auc, xgb_test_auc]\n",
    "}).sort_values('Test AUC', ascending=False)\n",
    "\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# En iyi model\n",
    "best_model_name = results.iloc[0]['Model']\n",
    "print(f'\\nEn iyi model: {best_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Model ve GÃ¶rselleÅŸtirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En iyi modeli seÃ§\n",
    "if best_model_name == 'LightGBM':\n",
    "    final_model = best_lgb\n",
    "    final_pred_proba = lgb_pred_proba\n",
    "else:\n",
    "    final_model = best_xgb\n",
    "    final_pred_proba = xgb_pred_proba\n",
    "\n",
    "final_pred = (final_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# GÃ¶rselleÅŸtirme\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC Curve\n",
    "ax1 = axes[0]\n",
    "fpr, tpr, _ = roc_curve(y_test, final_pred_proba)\n",
    "ax1.plot(fpr, tpr, 'b-', linewidth=2, label=f'{best_model_name} (AUC={roc_auc_score(y_test, final_pred_proba):.4f})')\n",
    "ax1.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Confusion Matrix\n",
    "ax2 = axes[1]\n",
    "cm = confusion_matrix(y_test, final_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax2,\n",
    "            xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "ax2.set_xlabel('Predicted')\n",
    "ax2.set_ylabel('Actual')\n",
    "ax2.set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/model_performance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, final_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SonuÃ§lar ve Ã–zet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"MODEL OPTÄ°MÄ°ZASYONU Ã–ZET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\"\"\n",
    "ðŸ“Š SONUÃ‡LAR\n",
    "{'â”€' * 40}\n",
    "Baseline CV AUC:        {baseline_scores.mean():.4f}\n",
    "LightGBM CV AUC:        {lgb_grid.best_score_:.4f}\n",
    "XGBoost CV AUC:         {xgb_grid.best_score_:.4f}\n",
    "\n",
    " SeÃ§ilen Model:       {best_model_name}\n",
    "   Test AUC:            {roc_auc_score(y_test, final_pred_proba):.4f}\n",
    "\n",
    "En Ä°yi Parametreler:\n",
    "\"\"\")\n",
    "\n",
    "if best_model_name == 'LightGBM':\n",
    "    for k, v in lgb_grid.best_params_.items():\n",
    "        print(f\"   {k}: {v}\")\n",
    "else:\n",
    "    for k, v in xgb_grid.best_params_.items():\n",
    "        print(f\"   {k}: {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dokumantasyon ve Notlar\n",
    "\n",
    "### Bu Notebook'ta Neler Yaptik?\n",
    "\n",
    "Bu calismada iki farkli gradient boosting algoritmasini (LightGBM ve XGBoost) karsilastirdik ve hiperparametre optimizasyonu yaptik.\n",
    "\n",
    "**Adimlar:**\n",
    "1. Onceki notebook'tan gelen feature set'i kullandik\n",
    "2. Duration sutununu cikardik cunku production ortaminda bu bilgi mevcut degil\n",
    "3. RandomizedSearchCV ile 50 farkli parametre kombinasyonu denedik\n",
    "4. Regularization parametreleri (L1, L2) ekledik\n",
    "5. Her iki modeli test seti uzerinde degerlendirdik\n",
    "\n",
    "### Sonuclar ve Yorumlar\n",
    "\n",
    "Duration olmadan elde ettigimiz ~0.79-0.80 AUC skoru bu veri seti icin gercekci ve iyi bir sonuc. Duration feature'i cikarildiginda performansin dusuk olmasi beklenen bir durum cunku bu degisken target ile cok guclu bir korelasyona sahipti.\n",
    "\n",
    "Hiperparametre optimizasyonu baseline'dan belirgin bir iyilesme saglamadi. Bu da modelin zaten iyi calistigini ve veri setinin sinirlarinda oldugumuzun bir gostergesi.\n",
    "\n",
    "### Onemli Kararlar\n",
    "\n",
    "- **Duration cikarildi:** Gercek dunya senaryosunda, bir musteri aramayi cevaplamadan once gorusme suresini bilemeyiz. Bu yuzden bu feature'i modelden cikarmak dogru bir karardi.\n",
    "\n",
    "- **Regularization:** Overfitting onlemek icin L1 ve L2 regularization parametreleri eklendi. Ancak mevcut durumda buyuk bir fark yaratmadi.\n",
    "\n",
    "- **Model secimi:** LightGBM ve XGBoost birbirine cok yakin performans gosterdi. Her iki model de production icin uygun.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
